{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c104d141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mast3r-slam/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading model from checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/RoMA-SLAM/thirdparty/mast3r/mast3r/model.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instantiating : AsymmetricMASt3R(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100',img_size=(512, 512), head_type='catmlp+dpt', output_mode='pts3d+desc24', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), patch_embed_cls='PatchEmbedDust3R', two_confs=True, desc_conf_mode=('exp', 0, inf), landscape_only=False)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from mast3r_slam.mast3r_utils import (\n",
    "    load_mast3r,\n",
    "    load_retriever,\n",
    "    mast3r_inference_mono,\n",
    ")\n",
    "from mast3r_slam.mast3r_utils import mast3r_match_asymmetric\n",
    "\n",
    "model = load_mast3r(device=\"cuda:0\")\n",
    "# model.share_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4e9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imA = np.array(Image.open(\"datasets/tum/rgbd_dataset_freiburg2_xyz/rgb/1311867170.462290.png\"))\n",
    "imA = imA.transpose(2,0,1)[None,...]\n",
    "imA = torch.from_numpy(imA / 255).float().cuda()\n",
    "\n",
    "imB = np.array(Image.open(\"datasets/tum/rgbd_dataset_freiburg2_xyz/rgb/1311867220.809727.png\"))\n",
    "imB = imB.transpose(2,0,1)[None,...]\n",
    "imB = torch.from_numpy(imB/255).float().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815cdc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 0.2448 seconds\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 37.06 MiB is free. Process 4179807 has 11.61 GiB memory in use. Of the allocated memory 11.17 GiB is allocated by PyTorch, and 146.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m elapsed_time = time.time() - start_time\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTime spent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m res11, res21 = \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m res = [res11, res21]\n\u001b[32m     24\u001b[39m X, C, D, Q = \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m     25\u001b[39m     *[(r[\u001b[33m\"\u001b[39m\u001b[33mpts3d\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m], r[\u001b[33m\"\u001b[39m\u001b[33mconf\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m], r[\u001b[33m\"\u001b[39m\u001b[33mdesc\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m], r[\u001b[33m\"\u001b[39m\u001b[33mdesc_conf\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res]\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecoder\u001b[39m\u001b[34m(model, feat1, feat2, pos1, pos2, shape1, shape2)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecoder\u001b[39m(model, feat1, feat2, pos1, pos2, shape1, shape2):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     dec1, dec2 = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(enabled=\u001b[38;5;28;01mFalse\u001b[39;00m, device_type=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      4\u001b[39m         res1 = model._downstream_head(\u001b[32m1\u001b[39m, [tok.float() \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m dec1], shape1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/RoMA-SLAM/thirdparty/mast3r/dust3r/dust3r/model.py:181\u001b[39m, in \u001b[36mAsymmetricCroCo3DStereo._decoder\u001b[39m\u001b[34m(self, f1, pos1, f2, pos2)\u001b[39m\n\u001b[32m    178\u001b[39m final_output.append((f1, f2))\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk1, blk2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.dec_blocks, \u001b[38;5;28mself\u001b[39m.dec_blocks2):\n\u001b[32m    180\u001b[39m     \u001b[38;5;66;03m# img1 side\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     f1, _ = \u001b[43mblk1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     \u001b[38;5;66;03m# img2 side\u001b[39;00m\n\u001b[32m    183\u001b[39m     f2, _ = blk2(*final_output[-\u001b[32m1\u001b[39m][::-\u001b[32m1\u001b[39m], pos2, pos1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mast3r-slam/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mast3r-slam/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/RoMA-SLAM/thirdparty/mast3r/dust3r/croco/models/blocks.py:187\u001b[39m, in \u001b[36mDecoderBlock.forward\u001b[39m\u001b[34m(self, x, y, xpos, ypos)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, xpos, ypos):\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.drop_path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxpos\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    188\u001b[39m     y_ = \u001b[38;5;28mself\u001b[39m.norm_y(y)\n\u001b[32m    189\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.drop_path(\u001b[38;5;28mself\u001b[39m.cross_attn(\u001b[38;5;28mself\u001b[39m.norm2(x), y_, y_, xpos, ypos))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mast3r-slam/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mast3r-slam/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/RoMA-SLAM/thirdparty/mast3r/dust3r/croco/models/blocks.py:105\u001b[39m, in \u001b[36mAttention.forward\u001b[39m\u001b[34m(self, x, xpos)\u001b[39m\n\u001b[32m    102\u001b[39m     q = \u001b[38;5;28mself\u001b[39m.rope(q, xpos)\n\u001b[32m    103\u001b[39m     k = \u001b[38;5;28mself\u001b[39m.rope(k, xpos)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m attn = \u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\n\u001b[32m    106\u001b[39m attn = attn.softmax(dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    107\u001b[39m attn = \u001b[38;5;28mself\u001b[39m.attn_drop(attn)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 37.06 MiB is free. Process 4179807 has 11.61 GiB memory in use. Of the allocated memory 11.17 GiB is allocated by PyTorch, and 146.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "def decoder(model, feat1, feat2, pos1, pos2, shape1, shape2):\n",
    "    dec1, dec2 = model._decoder(feat1, pos1, feat2, pos2)\n",
    "    with torch.amp.autocast(enabled=False, device_type=\"cuda\"):\n",
    "        res1 = model._downstream_head(1, [tok.float() for tok in dec1], shape1)\n",
    "        res2 = model._downstream_head(2, [tok.float() for tok in dec2], shape2)\n",
    "    return res1, res2\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "feat1, pos1, _ = model._encode_image(\n",
    "    imA, imA.shape\n",
    ")\n",
    "feat2, pos2, _ = model._encode_image(\n",
    "    imB, imB.shape\n",
    ")\n",
    "\n",
    "shape1, shape2 = imA.shape, imB.shape\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Time spent: {elapsed_time:.4f} seconds\")\n",
    "res11, res21 = decoder(model, feat1, feat2, pos1, pos2, shape1, shape2)\n",
    "res = [res11, res21]\n",
    "X, C, D, Q = zip(\n",
    "    *[(r[\"pts3d\"][0], r[\"conf\"][0], r[\"desc\"][0], r[\"desc_conf\"][0]) for r in res]\n",
    ")\n",
    "# 4xhxwxc\n",
    "X, C, D, Q = torch.stack(X), torch.stack(C), torch.stack(D), torch.stack(Q)\n",
    "X, C, D, Q = downsample(X, C, D, Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast3r-slam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
